{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[-1], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HwXoew2D2vT"
   },
   "source": [
    "## A Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0D7scqBWkg5t"
   },
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YACSvJ81h_Ry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image shape: (60000, 28, 28)\n",
      "Training label shape: (60000,)\n",
      "First five training labels: [5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('Training image shape:', x_train.shape) # (60000, 28, 28)\n",
    "print('Training label shape:', y_train.shape) # (60000,)\n",
    "print('First five training labels:', y_train[:5]) # array([5 0 4 1 9], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5xlStkakqJn"
   },
   "source": [
    "### Run the ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfnaDrkPiTTg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 13m 02s]\n",
      "val_loss: 0.30901777744293213\n",
      "\n",
      "Best val_loss So Far: 0.04718967527151108\n",
      "Total elapsed time: 00h 13m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1600 - accuracy: 0.9512\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0753 - accuracy: 0.9767\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0588 - accuracy: 0.9815\n",
      "WARNING:tensorflow:From /home/qq/.virtualenvs/book/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/qq/.virtualenvs/book/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(max_trials=2) # It tries two different models.\n",
    "\n",
    "# Feed the image classifier with training data \n",
    "# 20% of the data is used as validation data by default for tuning\n",
    "# the process may run for a bit long time, please try to use GPU\n",
    "clf.fit(x_train, y_train, epochs=3) # each model is trained for three epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the summarized results during the tuning process (return the best 10 models if existed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./image_classifier\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "image_block_1/block_type: vanilla\n",
      "image_block_1/normalize: True\n",
      "image_block_1/augment: False\n",
      "image_block_1/conv_block_1/kernel_size: 3\n",
      "image_block_1/conv_block_1/num_blocks: 1\n",
      "image_block_1/conv_block_1/num_layers: 2\n",
      "image_block_1/conv_block_1/max_pooling: True\n",
      "image_block_1/conv_block_1/separable: False\n",
      "image_block_1/conv_block_1/dropout: 0.25\n",
      "image_block_1/conv_block_1/filters_0_0: 32\n",
      "image_block_1/conv_block_1/filters_0_1: 64\n",
      "classification_head_1/spatial_reduction_1/reduction_type: flatten\n",
      "classification_head_1/dropout: 0.5\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "Score: 0.04718967527151108\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "image_block_1/block_type: resnet\n",
      "image_block_1/normalize: True\n",
      "image_block_1/augment: True\n",
      "image_block_1/image_augmentation_1/horizontal_flip: True\n",
      "image_block_1/image_augmentation_1/vertical_flip: True\n",
      "image_block_1/image_augmentation_1/contrast_factor: 0.0\n",
      "image_block_1/image_augmentation_1/rotation_factor: 0.0\n",
      "image_block_1/image_augmentation_1/translation_factor: 0.1\n",
      "image_block_1/image_augmentation_1/zoom_factor: 0.0\n",
      "image_block_1/res_net_block_1/pretrained: False\n",
      "image_block_1/res_net_block_1/version: resnet50\n",
      "image_block_1/res_net_block_1/imagenet_size: True\n",
      "classification_head_1/spatial_reduction_1/reduction_type: global_avg\n",
      "classification_head_1/dropout: 0\n",
      "optimizer: adam\n",
      "learning_rate: 0.001\n",
      "Score: 0.30901777744293213\n"
     ]
    }
   ],
   "source": [
    "clf.tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "cast_to_float32 (CastToFloat (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 28, 28, 1)         3         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                92170     \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 110,989\n",
      "Trainable params: 110,986\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = clf.export_model()\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Predict with the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPSNnpP6TDAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7']\n",
      " ['2']\n",
      " ['1']\n",
      " ...\n",
      " ['4']\n",
      " ['5']\n",
      " ['6']]\n"
     ]
    }
   ],
   "source": [
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_y[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENEc_5kaTJzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy: ', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_autokeras/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"model_autokeras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7567700e-10 3.5295128e-11 1.2154676e-08 ... 9.9999976e-01\n",
      "  2.6258207e-10 2.8395709e-08]\n",
      " [6.6249015e-08 6.2428267e-06 9.9999332e-01 ... 1.6883059e-13\n",
      "  1.5260402e-09 1.2889657e-12]\n",
      " [4.9405344e-08 9.9961913e-01 1.8153445e-05 ... 3.0194589e-05\n",
      "  2.4773601e-06 5.2960836e-08]\n",
      " ...\n",
      " [4.9813994e-13 4.9129406e-10 1.7102680e-12 ... 5.6733228e-07\n",
      "  1.4088409e-06 1.0516960e-06]\n",
      " [6.1794730e-10 2.8649080e-12 1.8733258e-10 ... 7.1567530e-11\n",
      "  1.2792475e-05 2.6690681e-09]\n",
      " [4.0928891e-09 8.4695960e-13 4.1557588e-08 ... 4.6263005e-14\n",
      "  1.5417026e-08 1.1706852e-10]]\n",
      "Test accuracy:  0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(\"model_autokeras\") # , custom_objects=ak.CUSTOM_OBJECTS\n",
    "\n",
    "predicted_y = loaded_model.predict(tf.expand_dims(x_test, -1))\n",
    "print(predicted_y)\n",
    "\n",
    "test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPg_anuHkux3"
   },
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BFjZCYilIcK"
   },
   "source": [
    "By default, AutoKeras use the last 20% of training data as validation data. As shown in the example below, you can use validation_split to specify the percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEnScrnyiVrk"
   },
   "outputs": [],
   "source": [
    "clf.fit(x_train,\n",
    "        y_train,\n",
    "        # Split the training data and use the last 15% as validation data.\n",
    "        validation_split=0.15,epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_HdBdJqlOwJ"
   },
   "source": [
    "You can also use your own validation set instead of splitting it from the training data with validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31XIV2zVjbxy"
   },
   "outputs": [],
   "source": [
    "split = 50000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(x_train,\n",
    "        y_train,\n",
    "        # Use your own validation set.\n",
    "        validation_data=(x_val, y_val),epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyT2hCbcl-bh"
   },
   "source": [
    "## Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4W38Em6fBqI"
   },
   "source": [
    "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
    "\n",
    "For the image, it accepts data formats both with and without the channel dimension. The images in the MNIST dataset do not have the channel dimension. Each image is a matrix with shape (28, 28). AutoKeras also accepts images of three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28, 28, 1).\n",
    "\n",
    "For the classification labels, AutoKeras accepts both plain labels, i.e. strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and 1s.\n",
    "\n",
    "So if you prepare your data in the following way, the ImageClassifier should still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JT_J3DONl76o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the images to have the channel dimension.\n",
    "# x_train = x_train.reshape(x_train.shape + (1,))\n",
    "# x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "\n",
    "# One-hot encode the labels.\n",
    "import numpy as np\n",
    "eye = np.eye(10)\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]\n",
    "\n",
    "print(x_train.shape) # (60000, 28, 28, 1)\n",
    "print(y_train.shape) # (60000, 10)\n",
    "print(y_train[:3])\n",
    "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPB_oEgtfH6r"
   },
   "source": [
    "We also support using tf.data.Dataset format for the training data. In this case, the images would have to be 3-dimentional. The labels have to be one-hot encoded for multi-class classification to be wrapped into tensorflow Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpFzehXBfLuO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train, ), (y_train, )))\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test, ), (y_test, )))\n",
    "\n",
    "clf = ak.ImageClassifier(max_trials=2)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurate search process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "clf = ak.ImageClassifier(max_trials=2, \n",
    "                         loss='categorical_crossentropy', \n",
    "                         metrics=['accuracy'],\n",
    "                         objective='val_accuracy',\n",
    "                        )\n",
    "\n",
    "clf.fit(x_train, y_train, \n",
    "        validation_split=0.15,\n",
    "        epochs=3, verbose=2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBykhsofDoKf"
   },
   "source": [
    "## Reference\n",
    "[ImageClassifier](/image_classifier),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[ImageBlock](/block/#imageblock-class),\n",
    "[Normalization](/preprocessor/#normalization-class),\n",
    "[ImageAugmentation](/preprocessor/#image-augmentation-class),\n",
    "[ResNetBlock](/block/#resnetblock-class),\n",
    "[ImageInput](/node/#imageinput-class),\n",
    "[ClassificationHead](/head/#classificationhead-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
